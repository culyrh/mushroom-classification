# Mushroom Classification
**Binary Classification of Edible vs Poisonous Mushrooms**

<br>

ë²„ì„¯ì˜ í˜•íƒœÂ·ìƒ‰ìƒÂ·í‘œë©´Â·ê³„ì ˆ ë“± **20ê°œì˜ ì™¸í˜•ì  feature**ë¥¼ í™œìš©í•´
ë²„ì„¯ì´ **ë¨¹ì„ ìˆ˜ ìˆëŠ”ì§€(edible)** ë˜ëŠ” **ë…ì„±(poisonous)** ì¸ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” <b>ì´ì§„ ë¶„ë¥˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸</b>ì…ë‹ˆë‹¤. 
ì‹¤ì œ ì„­ì·¨ ì—¬ë¶€ íŒë‹¨ì— ì‚¬ìš©í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

<br>

## êµ¬í˜„ ì¡°ê±´

- Python built-in ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì‚¬ìš© (scikit-learn ê¸ˆì§€)
- ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ì„ **ìˆ˜ì‹ë¶€í„° êµ¬í˜„**

<br>

## Dataset

- https://www.kaggle.com/datasets/uciml/mushroom-classification

- mushroom.csv: ë²„ì„¯ 61,069ê°œì˜ í•™ìŠµìš© ë°ì´í„°ë¡œ, 20ê°œì˜ feature(cap, gill, stem, color, habitat, season ë“±)ì™€
edible/poisonous ì´ì§„ ë ˆì´ë¸”ì„ í¬í•¨í•œ ëª¨ë¸ í•™ìŠµÂ·í‰ê°€ìš© ë°ì´í„°ì…‹

- mushroom_meta.txt: mushroom.csvì— í¬í•¨ëœ 20ê°œ featureì˜ ìƒì„¸í•œ ì˜ë¯¸Â·ë²”ì£¼ê°’Â·ì½”ë“œ ì„¤ëª…ì„ ë‹´ì€ ë©”íƒ€ë°ì´í„° íŒŒì¼ë¡œ,
ê° ë³€ìˆ˜ì˜ ê°’ì´ ì–´ë–¤ ìƒë¬¼í•™ì  íŠ¹ì„±ì„ ë‚˜íƒ€ë‚´ëŠ”ì§€ ì°¸ê³ í•˜ê¸° ìœ„í•œ ë¬¸ì„œ

<br>

| í•­ëª©            | ë‚´ìš©                                                           |
|-----------------|----------------------------------------------------------------|
| ë°ì´í„° ìˆ˜       | 61,069ê°œ                                                   |
| í´ë˜ìŠ¤          | e = edible, p = poisonous                                  |
| Feature ê°œìˆ˜    | ì´ 20ê°œ                                                        |
| Feature íƒ€ì…    | **17ê°œ ëª…ëª©í˜•(nominal)** + **3ê°œ ìˆ˜ì¹˜í˜•(metrical)**           |
| ë°ì´í„° íŠ¹ì§•     | synthetic dataset (ëœë¤ ê¸°ë°˜)                                   |
| ì£¼ìš” ë³€ìˆ˜       | cap, gill, stem, veil, color, habitat, season ë“± 20ê°œ ì†ì„±     |

<br>

### Feature ì˜ˆì‹œ ìš”ì•½  
- `cap-diameter` (m): ëª¨ì ì§€ë¦„  
- `cap-shape` (n): bell, conical, convex, flat ë“±  
- `cap-surface`, `stem-surface`: scaly, fibrous, smooth ë“±  
- `cap-color`, `gill-color`, `stem-color`: ë‹¤ì–‘í•œ ìƒ‰ìƒ ì½”ë“œ  
- `habitat`: woods, meadows, urban ë“±  
- `season`: spring, summer, autumn, winter  

(ëª…ëª©í˜• featureëŠ” ëª¨ë‘ **1ê¸€ì ì½”ë“œ**ë¡œ ì¸ì½”ë”©ë˜ì–´ ìˆì–´ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë§¤í•‘ì´ í•„ìš”í•©ë‹ˆë‹¤)

<br>

## êµ¬í˜„ ì•Œê³ ë¦¬ì¦˜ ìš”ì•½

### 1. Decision Tree (ID3)
- Entropy / Information Gain ê¸°ë°˜ ë¶„ê¸°  
- ëª…ëª©í˜• featureì— ëŒ€í•´ valueë³„ split  
- Tree Depth ì œí•œ ì ìš©  
- ë°ì´í„° ëœë¤ì„±ì´ ë†’ì•„ ì¼ë°˜í™” ì„±ëŠ¥ì€ ì œí•œë¨

<br>

### 2ï¸. k-Nearest Neighbors (kNN)
- ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜(Euclidean)  
- ëª…ëª©í˜• feature â†’ ì¼ì¹˜ ì—¬ë¶€ 0/1 ì²˜ë¦¬  
- k = 5 ì„¤ì •  
- ì‹¤í—˜ ê²°ê³¼ ê°€ì¥ ë†’ì€ accuracy ë‹¬ì„±  

<br>

### 3. Naive Bayes
- Feature ë…ë¦½ ê°€ì •  
- ëª…ëª©í˜• feature â†’ ë¹ˆë„ ê¸°ë°˜ í™•ë¥  + Laplace smoothing  
- ìˆ˜ì¹˜í˜• feature â†’ Gaussian  
- ë§¤ìš° ë¹ ë¥´ê³  baseline ì„±ëŠ¥ ìš°ìˆ˜  

<br>

### 4. Neural Network (2-layer MLP)
- hidden layer 16, activation = sigmoid  
- binary cross-entropy  
- backpropagation ì§ì ‘ êµ¬í˜„  
- synthetic ë°ì´í„° íŠ¹ì„±ìƒ ë†’ì€ ì„±ëŠ¥ì€ ì–´ë ¤ì›€  

<br>

### 5. Support Vector Machine (Linear SVM)
- Hinge loss + Gradient Descent  
- Kernel ë¯¸ì‚¬ìš©(ì§ì ‘ êµ¬í˜„ ë‚œì´ë„ ê³ ë ¤)  
- ì„ í˜• ë¶„ë¦¬ ì–´ë ¤ìš´ ë°ì´í„° â†’ ë‚®ì€ accuracy  

<br>

### ì •í™•ë„(accuracy) ê²°ê³¼

| Algorithm        | Accuracy |
|------------------|----------|
| **kNN (k=5)**    | **0.8819** |
| Naive Bayes      | 0.8039 |
| Decision Tree    | 0.5549 |
| Neural Network   | 0.5549 |
| SVM (Linear)     | 0.5417 |

> kNNì´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡ (synthetic + ë²”ì£¼í˜• ë¹„ì¤‘ ë†’ì€ ë°ì´í„° íŠ¹ì„±)

<br>

<br>

ğŸ„ğŸ„ğŸ„.................